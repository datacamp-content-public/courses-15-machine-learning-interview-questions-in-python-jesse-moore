---
title: Insert title here
key: 043ea510d97468d9de9662eddff29a67

---
## Question 7: Handling and Preparing Time Series Data for Training

```yaml
type: "TitleSlide"
key: "c3b9a3d56a"
```

`@lower_third`

name: Jesse Moore
title: Data Scientist


`@script`
Great job, you've made it to the final question on data preperation. 

In this video, you'll learn how to answer interview questions on preparing time-series data for machine learning.


---
## What is Time Series Data?

```yaml
type: "FullSlide"
key: "93726b0c11"
center_content: false
```

`@part1`
![](https://i.imgur.com/lAm3EKQ.png){{1}}

- Time series data is time-ordered, typically in even spaces of time{{2}}

- Needs to be handled in a special way when preparing training and validation data{{3}}


`@script`
Time series data is a special type of data.

One of the most obvious examples of time-series data is the stock market. The prices in the previous days are very predictive of the prices today.

Due to this chronological nature, time series data needs to be handled in a special way. 

When preparing training and validation sets we need to be very cognizant of the potential pitfalls and understand how to deal with them.

There are many variations of questions on time series data, but the concept behind them remains the same.


---
## The Concept Behind Preparing Time Series Data

```yaml
type: "TwoColumns"
key: "91b971f23b"
```

`@part1`
- Random sampling assumes there is no relationship between data points{{1}}

- Be careful to avoid "Look-ahead" bias {{3}}

- Keep in mind what would be available at prediction time {{4}}


`@part2`
![](https://i.imgur.com/ahCOkRA.png) {{2}}


`@script`
Imagine an example where you did not build a training and validation set in the right way. You have simply randomly selected rows to train and validate on.

In this case, your algorithm could determine from some of the features in the dataset to "Look Ahead".

It is best to think of what an algorithm might do as fingerprinting.

Let's say you are making a prediction today which is June 20th. 

You want to predict what will happen tomorrow on the 21st, but because you have not dealt with the chronological nature of the time-series data, your algorithm is able to find the results from June 26th and 'cheat' with information that it would otherwise not have.

The result would be an algorithm that tests very well, but fails in practice. 

When the algorithm goes live it is not privy to the future information it has become accustomed to using. 

The effect of this varies from dataset to dataset, but the concept remains the same. Do not give your algorithm future information!


---
## Preparing the Data

```yaml
type: "FullImageSlide"
key: "a74885e2f0"
center_content: true
disable_transition: false
```

`@part1`
![](https://i.imgur.com/APiGy52.png)


`@script`
We prepare the data by ensuring that the training data precedes the validation data. 

In the chart, the red area denotes the data that will be set for training and the blue area for validation. 

Let's walkthrough an example using air quality data available from the [Madrid City Council](https://www.kaggle.com/decide-soluciones/air-quality-madrid/home)


---
## Madrid Air Quality Data

```yaml
type: "TwoColumns"
key: "46c5fcb3f9"
```

`@part1`
```python
air_df.head()
```


`@part2`
![](https://i.imgur.com/31eQGJ8.png)


`@script`
We are going to look at a simple version of the dataset. We have available air_df, a dataset that contains data for one sensor in madrid for 2017.

PM10 and PM2.5 are the sensor readings for particles under 10 micrometers and 2.5 micrometers respectively. All measurements are in micrograms per cubic meter.

Air_df contains 8688 rows, one for each hour in that year. I have taken the liberty of forward-filling missing values in the dataset already.


---
## Preparing the Data

```yaml
type: "FullCodeSlide"
key: "e6609a80bf"
```

`@part1`
```python
air_df.sort_values('date', inplace=True)  #Sort Values 
for timestep in range(1, 4, 1): #3 timesteps
    #Append previous datapoints for each row
    air_df['PM10_t-' + str(timestep)] = air_df['PM10'].shift(timestep)
    air_df['PM25_t-' + str(timestep)] = air_df['PM25'].shift(timestep)
```{{1}}

```python
air_df.dropna(inplace=True)  #Drop NA's produced by shifting the timesteps
air_df.drop('PM10', axis=1, inplace=True)  #Remove PM10 for each timestep
air_df.head()
```{{2}}

![](https://i.imgur.com/st4eSYm.png){{3}}


`@script`
First, we write a for loop that produces the training data. 

As our predictor values, we will use that last 3 readings from the sensor and we will try to predict PM 2.5 readings (the more dangerous of the two).

We start by ordering the data and using pandas shift function multiple times to build our training dataset. 

We then drop the NA values produced, remove the PM10 column as we will only be predicting PM2.5 values, and take a look at our dataset.

Almost there.


---
## Training and Validation Split

```yaml
type: "FullSlide"
key: "53a1620a33"
```

`@part1`
```python
#Find index to split on
num_rows = air_df.shape[0]
split_ix = round(num_rows * 0.75)
```{{1}}

```python
#Create train and validation datasets
air_df.drop('date', axis=1, inplace=True)
train_df = air_df[0:split_ix]
val_df = air_df[split_ix:]
```{{2}}

```python
train_df.head()
```{{3}}
![](https://i.imgur.com/d0A3Y8j.png){{4}}


`@script`
Now, we are ready to split our data. 

Keeping in mind the earlier part of this video, we will split the data using the ordered Pandas data frame.

First, we find the index to split on using our ordered data frame.

We drop the date column, and produce the final datasets.

We're ready for modeling.


---
## Test Yourself

```yaml
type: "FinalSlide"
key: "7c729ed8fa"
```

`@script`
Time for you to try it out yourself.

